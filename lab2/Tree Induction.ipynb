{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from anytree import Node, RenderTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# returns tuple: (most frequent class in D, there is only one class in D)\n",
    "def get_most_freq_class(D, c_name):\n",
    "    class_values = D[c_name].values\n",
    "    class_to_freq = {}\n",
    "    \n",
    "    for data in class_values:\n",
    "        #TODO: find class\n",
    "        class_val = data\n",
    "\n",
    "        if class_val in class_to_freq:\n",
    "            class_to_freq[class_val] = class_to_freq[class_val] + 1\n",
    "        else:\n",
    "            class_to_freq[class_val] = 1\n",
    "\n",
    "    total = 0\n",
    "    max_freq = 0\n",
    "    max_class = None\n",
    "\n",
    "    for k, v in class_to_freq.items():\n",
    "\n",
    "        if v > max_freq:\n",
    "            max_freq = v\n",
    "            max_class = k\n",
    "\n",
    "        total += v\n",
    "\n",
    "    return (max_class, total == max_freq)\n",
    "\n",
    "# uses information gain\n",
    "# returns attr with largest gain else None if all gain < threshold\n",
    "def select_split_attr_reg(D, A,c_name,threshold):\n",
    "    \n",
    "    #TODO: build get_entropy()\n",
    "    #Get entropy of the data set, pass in the class column name\n",
    "    entropy = entropy_d(D[c_name])\n",
    "    max_gain = threshold\n",
    "    best_attr = None\n",
    "\n",
    "    for attr in A:\n",
    "        #TODO: build get_entropy()\n",
    "        #We are doing a groupby by the attribute and getting\n",
    "        #a dataframe with the class frequencies\n",
    "        SD = D.groupby([attr,c_name]).size().to_frame()\n",
    "        SD.reset_index(inplace=True)\n",
    "        SD.rename(columns = {0:\"count\"},inplace = True)\n",
    "        #Entropy of the attribute\n",
    "        entropy_of_split = entropy_a(SD, attr)\n",
    "        gain = entropy - entropy_of_split\n",
    "        \n",
    "        if gain > max_gain:\n",
    "            max_gain = gain\n",
    "            best_attr = attr\n",
    "\n",
    "    return best_attr\n",
    "\n",
    "# uses information gain ratio\n",
    "def select_split_attr_ratio(D, A, c_name, threshold):\n",
    "\n",
    "    #TODO: build get_entropy()\n",
    "    entropy = entropy_d(D[c_name])\n",
    "    max_gainRatio = threshold\n",
    "    best_attr = None\n",
    "\n",
    "    for attr in A:\n",
    "        SD = D.groupby([attr,c_name]).size().to_frame()\n",
    "        SD.reset_index(inplace=True)\n",
    "        SD.rename(columns = {0:\"count\"},inplace = True)\n",
    "        \n",
    "        #TODO: build get_entropy()\n",
    "        entropy_of_split = entropy_a(SD, attr)\n",
    "        gain = entropy - entropy_of_split\n",
    "        gainRatio = gain / entropy_of_split\n",
    "        \n",
    "        if gainRatio > max_gainRatio:\n",
    "            max_gainRatio = gainRatio\n",
    "            best_attr = attr\n",
    "\n",
    "    return best_attr\n",
    "\n",
    "def build_decision_tree(dataset, attributes, tree, threshold,c_name):\n",
    "    most_freq_class, is_only_class = get_most_freq_class(dataset,c_name)\n",
    "\n",
    "    if is_only_class or len(attributes) == 0:\n",
    "        leaf = Node(most_freq_class)\n",
    "        tree = leaf\n",
    "        return tree\n",
    "    else:\n",
    "        split_attr = select_split_attr_reg(dataset, attributes,\n",
    "                                           c_name,threshold)\n",
    "\n",
    "        if split_attr is None:\n",
    "            leaf = Node(most_freq_class)\n",
    "            tree = leaf\n",
    "            return tree\n",
    "        else:\n",
    "            parent = Node(split_attr)\n",
    "            \n",
    "            attr_val_to_data = {}            \n",
    "            for index,data in dataset.iterrows():\n",
    "                # TODO: correct indexing\n",
    "                attr_val = data[split_attr]\n",
    "\n",
    "                if attr_val not in attr_val_to_data:\n",
    "                    attr_val_to_data[attr_val] = []\n",
    "                attr_val_to_data[attr_val].append(data)\n",
    "            for k, v in attr_val_to_data.items():\n",
    "                \n",
    "                #new_df = pd.DataFrame(data = v,columns = attributes + [c_name])\n",
    "                #print(new_df.columns)\n",
    "                child = build_decision_tree(pd.DataFrame(data = v,columns = attributes + [c_name]), \n",
    "                                            [attr for attr in attributes if attr != split_attr],\n",
    "                                            None,threshold,c_name)\n",
    "                child.parent = parent\n",
    "\n",
    "            return parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup():\n",
    "    y_vars = {}\n",
    "    df = pd.read_csv(\"data/tree03-20-words.csv\",skiprows=[1,2])\n",
    "    df.drop(\"Id\",inplace = True,axis = 1)\n",
    "    for col in df.columns:\n",
    "        y_vars[col] = list(set(df[col]))\n",
    "    y_vars\n",
    "    return[df,y_vars]\n",
    "\n",
    "def entropy_d(d):\n",
    "    freqs = d.value_counts().values\n",
    "    tot_n = np.sum(freqs)\n",
    "    entropy = 0 \n",
    "    #Sums up all of the entropys for each possible value for a given\n",
    "    #attribute Ai\n",
    "    for f in freqs:\n",
    "        entropy += -(f/tot_n)*math.log((f/tot_n),2)\n",
    "    return entropy\n",
    "\n",
    "#D = the original data\n",
    "#Di = data subset after the partition/split\n",
    "def gain(split_data,a_name,r_list):\n",
    "    return entropy_d(r_list) - entropy_a(split_data,a_name)\n",
    "def gain_ratio(df, a_name, resp):   \n",
    "    split_data = df[[a_name, resp]]\n",
    "    #pd.pivot_table(temp, index = \"Education\",columns = 'Vote')\n",
    "    split_data = split_data.groupby([a_name, resp]).size().to_frame()\n",
    "    split_data.reset_index(inplace=True)\n",
    "    split_data.rename(columns = {0:\"count\"},inplace = True)\n",
    "\n",
    "    edges = list(set(split_data[a_name]))\n",
    "    a_sum = 0\n",
    "    for edge in edges:\n",
    "        edge_df = split_data[split_data[a_name] == edge]\n",
    "        prop = np.sum(edge_df['count'])/np.sum(split_data['count'])\n",
    "        a_sum += -prop * math.log(prop,2)\n",
    "    return gain(split_data,a_name,df[resp])/a_sum\n",
    "\n",
    "def entropy_a(split_data, a_name):\n",
    "    edges = list(set(split_data[a_name]))\n",
    "    a_sum = 0\n",
    "    for edge in edges:\n",
    "        edge_df = split_data[split_data[a_name] == edge]\n",
    "        prop = np.sum(edge_df['count'])/np.sum(split_data['count'])\n",
    "        counts = edge_df['count']\n",
    "        entropy_d = 0\n",
    "        for c in counts:\n",
    "            prop_d = c/np.sum(edge_df['count'])\n",
    "            entropy_d += -prop_d * math.log(prop_d,2)   \n",
    "        \n",
    "        a_sum += prop * entropy_d\n",
    "    return a_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = setup()\n",
    "df = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('McCain', False)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_freq_class(df,\"Vote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node('/Bush Approval')\n",
      "├── Node('/Bush Approval/Religion')\n",
      "│   ├── Node('/Bush Approval/Religion/Gender')\n",
      "│   │   ├── Node('/Bush Approval/Religion/Gender/Obama')\n",
      "│   │   └── Node('/Bush Approval/Religion/Gender/McCain')\n",
      "│   ├── Node('/Bush Approval/Religion/Obama')\n",
      "│   └── Node('/Bush Approval/Religion/McCain')\n",
      "└── Node('/Bush Approval/McCain')\n"
     ]
    }
   ],
   "source": [
    "tree = build_decision_tree(df,list(df.columns[:-1]),None,.05,\"Vote\")\n",
    "print(RenderTree(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bush Approval</th>\n",
       "      <th>Vote</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Approve</td>\n",
       "      <td>McCain</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disapprove</td>\n",
       "      <td>McCain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disapprove</td>\n",
       "      <td>Obama</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Bush Approval    Vote  count\n",
       "0       Approve  McCain      7\n",
       "1    Disapprove  McCain      3\n",
       "2    Disapprove   Obama     10"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data = df[[\"Bush Approval\",\"Vote\"]]\n",
    "#pd.pivot_table(temp, index = \"Education\",columns = 'Vote')\n",
    "split_data = split_data.groupby([\"Bush Approval\",\"Vote\"]).size().to_frame()\n",
    "split_data.reset_index(inplace=True)\n",
    "split_data.rename(columns = {0:\"count\"},inplace = True)\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13961680570909832"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_ratio(df,\"Education\",\"Vote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Political Party',\n",
       " 'Ideology',\n",
       " 'Race',\n",
       " 'Gender',\n",
       " 'Religion',\n",
       " 'Family Income',\n",
       " 'Education',\n",
       " 'Age',\n",
       " 'Region',\n",
       " 'Bush Approval']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node('/Bush Approval')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
